<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>GHOSTLOOP — The Ghost Project</title>
  <meta name="description" content="Drag a loop. We analyze the first seconds, detect onsets, slice tiny grains from your loop and re‑arrange them into a brand‑new pattern — locally in your browser."/>
  <link rel="icon" href="data:,"/>
  <!-- Minimal YGP neon aesthetic via Tailwind CDN for speed -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Audio libs -->
  <script src="https://unpkg.com/tone@14.8.49/build/Tone.js"></script>
  <script src="https://unpkg.com/meyda/dist/web/meyda.min.js"></script>
  <script src="https://unpkg.com/web-audio-beat-detector/dist/index.umd.js"></script>
  <style>
    :root{ --bg:#070a0f; --ink:#e6f0ff; --accent:#00e5ff; --accent2:#a855f7; }
    html,body{height:100%;background:
      radial-gradient(1200px 800px at 80% -10%, rgba(168,85,247,.12), transparent),
      radial-gradient(1000px 700px at -10% 110%, rgba(0,229,255,.10), transparent),
      var(--bg);color:var(--ink)}
    .title{font-weight:900;letter-spacing:.4px;background:linear-gradient(90deg,var(--accent),var(--accent2));-webkit-background-clip:text;background-clip:text;color:transparent}
    .drop{border:2px dashed rgba(255,255,255,.22);border-radius:16px;padding:28px;text-align:center;cursor:pointer;transition:.2s}
    .drop.drag{border-color:var(--accent);background:rgba(0,229,255,.06)}
    .glass{background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.08);backdrop-filter:blur(8px)}
    .link{color:var(--accent)}
  </style>
</head>
<body>
  <main class="max-w-xl mx-auto p-5 min-h-screen flex flex-col gap-6">
    <h1 class="title text-4xl text-center mt-8">GHOSTLOOP</h1>
    <section id="panel" class="glass rounded-2xl p-4">
      <div id="dz" class="drop">
        <p class="text-center">Drag & drop a <b>.wav/.aif/.mp3</b><br/><span class="text-xs text-slate-400">Nothing is uploaded. All processing is local.</span></p>
        <input id="file" class="hidden" type="file" accept=".wav,.aif,.aiff,.mp3,.flac,.m4a,audio/*"/>
      </div>
      <p id="status" class="text-xs text-slate-400 mt-3">Waiting for file…</p>
      <div id="actions" class="hidden mt-2 text-sm">
        <button id="play" class="underline">Play / Pause</button>
        <span class="mx-2">·</span>
        <a id="dl" class="link" href="#" download="ghostloop.wav">Download WAV</a>
      </div>
    </section>
    <p class="text-[11px] text-slate-500 text-center">This prototype rearranges tiny slices of your loop into a new rhythm and texture. Avoid dragging copyrighted material you can’t legally use in a composition.</p>
  </main>

<script>
const AC = new (window.AudioContext||window.webkitAudioContext)();
const MAX_SECS = 8; // analyze/slice first 8s for stability
let srcBuf = null;         // original AudioBuffer
let bpm = 100;             // detected bpm fallback
let schedule = null;       // Tone.Part
let recorder = null;       // Tone.Recorder
let downloadURL = null;    // rendered wav url

// UI elems
const dz = document.getElementById('dz');
const file = document.getElementById('file');
const statusEl = document.getElementById('status');
const actions = document.getElementById('actions');
const playBtn = document.getElementById('play');
const dl = document.getElementById('dl');

function db(m){ statusEl.textContent = m; }

// Helpers
function toMono(buf){
  if (buf.numberOfChannels===1) return buf;
  const out = AC.createBuffer(1, buf.length, buf.sampleRate);
  const L = buf.getChannelData(0), R = buf.getChannelData(1);
  const ch = out.getChannelData(0);
  for(let i=0;i<buf.length;i++) ch[i] = 0.5*(L[i]+R[i]);
  return out;
}
function firstSeconds(buf, secs){
  const n = Math.min(buf.length, Math.floor(secs*buf.sampleRate));
  const out = AC.createBuffer(buf.numberOfChannels, n, buf.sampleRate);
  for(let c=0;c<buf.numberOfChannels;c++) out.copyToChannel(buf.getChannelData(c).subarray(0,n), c);
  return out;
}

// Simple spectral flux onset detection
async function onsetFlux(buf, frame=1024, hop=512){
  const mono = toMono(buf).getChannelData(0);
  const frames = Math.max(0, Math.floor((mono.length-frame)/hop));
  const flux = new Float32Array(frames);
  let prevSpec = new Float32Array(frame/2);
  const hann = new Float32Array(frame);
  for(let i=0;i<frame;i++) hann[i]=0.5*(1-Math.cos(2*Math.PI*i/(frame-1)));
  for(let f=0; f<frames; f++){
    const start = f*hop; if(start+frame>=mono.length) break;
    // naive DFT mag spectrum (sufficient at 22k)
    const bins = frame/2; const mag = new Float32Array(bins);
    for(let k=0;k<bins;k++){
      let re=0,im=0; const angK=-2*Math.PI*k/frame;
      for(let n=0;n<frame;n++){
        const x=(mono[start+n]||0)*hann[n]; const ang=angK*n; re+=x*Math.cos(ang); im+=x*Math.sin(ang);
      }
      mag[k]=Math.hypot(re,im);
    }
    let sum=0; for(let k=0;k<bins;k++){ const d=Math.max(0, mag[k]-prevSpec[k]); sum+=d; }
    flux[f]=sum; prevSpec=mag;
    if (f%60===0) await new Promise(r=>setTimeout(r,0));
  }
  // normalize and pick peaks
  const max = Math.max(...flux)||1; for(let i=0;i<flux.length;i++) flux[i]/=max;
  const peaks=[]; const thr=0.22; const minDist=6; // frames (~6*hop/sampleRate s)
  for(let i=2;i<flux.length-2;i++){
    if (flux[i]>thr && flux[i]>flux[i-1] && flux[i]>flux[i+1]){
      if (peaks.length===0 || i-peaks[peaks.length-1]>minDist) peaks.push(i);
    }
  }
  return { flux, peaks, hop, sr: buf.sampleRate };
}

// Feature for rough class by centroid (kick/snare/hat)
function centroid(frame, sr){
  let num=0, den=0; for(let i=0;i<frame.length;i++){ const mag=frame[i]; const f=i*sr/(frame.length*2); num += f*mag; den += mag; }
  return den? num/den : 0;
}

function classifyPeaks(buf, env){
  const mono = toMono(buf).getChannelData(0); const sr=env.sr; const frame=1024; const half=512;
  const classes = {kick:[], snare:[], hat:[], perc:[]};
  for(const p of env.peaks){
    const start = p*env.hop; const s = Math.max(0, start-half);
    const slice = mono.subarray(s, Math.min(mono.length, s+frame));
    // tiny spectrum for centroid
    const bins = frame/2; let re,im; const mag=new Float32Array(bins);
    for(let k=0;k<bins;k++){ re=0; im=0; const angK=-2*Math.PI*k/frame; for(let n=0;n<slice.length && n<frame;n++){ const x=slice[n]; const ang=angK*n; re+=x*Math.cos(ang); im+=x*Math.sin(ang);} mag[k]=Math.hypot(re,im); }
    const c = centroid(mag, sr);
    if (c<140) classes.kick.push(start/sr);
    else if (c<800) classes.snare.push(start/sr);
    else if (c<4000) classes.hat.push(start/sr);
    else classes.perc.push(start/sr);
  }
  return classes;
}

async function detectBPM(buf){
  try{ const b = await window.webAudioBeatDetector.getBpm(buf); return Math.round(b); }
  catch(e){ console.warn('BPM fail', e); return 100; }
}

// Build new pattern using grains from source at given offsets
async function buildPattern(buf, offsets, bpm){
  // FX chain for modern polish
  const comp = new Tone.Compressor({threshold:-18, ratio:3}).toDestination();
  const limiter = new Tone.Limiter(-0.8).toDestination();
  comp.connect(limiter);
  const reverb = new Tone.Reverb({decay:2.2, wet:0.15}).connect(comp);
  const delay = new Tone.FeedbackDelay({delayTime:0.25, feedback:0.22, wet:0.12}).connect(comp);
  const eq = new Tone.EQ3({low:0, mid:0, high:1}).connect(comp);

  // One GrainPlayer that reuses the same buffer at different offsets
  const gKick = new Tone.GrainPlayer({ url: buf, grainSize:0.08, overlap:0.02, playbackRate:1, loop:false }).connect(eq);
  const gSnare= new Tone.GrainPlayer({ url: buf, grainSize:0.09, overlap:0.03, playbackRate:1, loop:false }).connect(reverb);
  const gHat  = new Tone.GrainPlayer({ url: buf, grainSize:0.04, overlap:0.02, playbackRate:1.2, loop:false }).connect(eq);
  const gPerc = new Tone.GrainPlayer({ url: buf, grainSize:0.06, overlap:0.02, playbackRate:1, loop:false }).connect(delay);
  [gKick,gSnare,gHat,gPerc].forEach(g=> g.sync().start(0));

  Tone.Transport.bpm.value = bpm;
  const bars = 8; const ev=[];
  const rnd = (a)=> a[Math.floor(Math.random()*a.length)] ?? 0;
  // reduce offset arrays for stability
  const K = offsets.kick.slice(0,16), S = offsets.snare.slice(0,16), H = offsets.hat.slice(0,64), P = offsets.perc.slice(0,32);
  for(let b=0;b<bars;b++){
    ev.push([`${b}:0:0`, {t:'k',o:rnd(K)}]);
    ev.push([`${b}:1:0`, {t:'s',o:rnd(S)}]);
    ev.push([`${b}:3:0`, {t:'s',o:rnd(S)}]);
    for(let s=0;s<16;s++){ if (Math.random()<0.35) ev.push([`${b}:${Math.floor(s/4)}:${s%4}`, {t:'h',o:rnd(H)}]); }
    if (Math.random()<0.5) ev.push([`${b}:2:0`, {t:'k',o:rnd(K)}]);
    if (Math.random()<0.35) ev.push([`${b}:2:2`, {t:'p',o:rnd(P)}]);
  }
  if (schedule) schedule.dispose();
  schedule = new Tone.Part((time, d)=>{
    const offs = d.o||0; // seconds in source
    if (d.t==='k') gKick.start(time, offs);
    if (d.t==='s') gSnare.start(time, offs);
    if (d.t==='h') gHat.start(time, offs);
    if (d.t==='p') gPerc.start(time, offs);
  }, ev).start(0);

  // record
  if (!recorder) recorder = new Tone.Recorder();
  Tone.getDestination().connect(recorder);
  Tone.Transport.start();
  const seconds = (bars*4) * (60/bpm);
  recorder.start();
  setTimeout(async ()=>{
    const blob = await recorder.stop();
    if (downloadURL) URL.revokeObjectURL(downloadURL);
    downloadURL = URL.createObjectURL(blob);
    document.getElementById('dl').href = downloadURL;
    actions.classList.remove('hidden');
    db('Done. Play or Download your new loop.');
  }, (seconds+0.25)*1000);
}

async function processFile(f){
  db('Decoding…');
  const ab = await f.arrayBuffer();
  const buf = await AC.decodeAudioData(ab);
  srcBuf = firstSeconds(buf, MAX_SECS);
  db('Analyzing…');
  const b = await detectBPM(srcBuf); bpm = b || 100;
  const env = await onsetFlux(srcBuf, 1024, 512);
  const offsets = classifyPeaks(srcBuf, env);
  db(`BPM ${bpm} — generating…`);
  await Tone.start();
  // pass original buffer into Tone.ToneAudioBuffer for GrainPlayer
  const tBuf = new Tone.ToneAudioBuffer(srcBuf);
  await buildPattern(tBuf, offsets, bpm);
}

// UI wiring: minimal — just title + drop zone; autoplay on drop
function handleDropFiles(files){
  const f = files?.[0];
  if(!f){ db('No audio file detected.'); return; }
  if(!f.type.startsWith('audio') && !/\.(wav|aif|aiff|mp3|flac|m4a)$/i.test(f.name||'')){
    db('Not an audio file. Use .wav/.aif/.mp3'); return; }
  processFile(f).catch(e=>{ console.error(e); db('Error while processing. Try a shorter loop.'); });
}

// Dropzone
dz.addEventListener('click', ()=> file.click());
file.addEventListener('change', e=> handleDropFiles(e.target.files));
dz.addEventListener('dragover', e=>{ e.preventDefault(); dz.classList.add('drag'); });
dz.addEventListener('dragleave', ()=> dz.classList.remove('drag'));
dz.addEventListener('drop', e=>{ e.preventDefault(); dz.classList.remove('drag'); const dt=e.dataTransfer; if(dt?.files&&dt.files.length) handleDropFiles(dt.files); else db('Drag the actual audio file (export from Splice first).'); });

// Minimal controls
let playing=false;
playBtn.addEventListener('click', async ()=>{
  await Tone.start();
  if (!playing){ Tone.Transport.start(); playBtn.textContent='Pause'; playing=true; }
  else { Tone.Transport.pause(); playBtn.textContent='Play'; playing=false; }
});
</script>
</body>
</html>
