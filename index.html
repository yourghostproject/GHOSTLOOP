<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>GHOSTLOOP — The Ghost Project</title>
  <meta name="description" content="Drag a melodic loop. We analyze a short slice, then granularly recompose FIVE new loops from your own audio — locally, no uploads."/>
  <link rel="icon" href="data:,"/>
  <!-- Minimal YGP neon aesthetic via Tailwind CDN for speed -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Audio libs (all local/browser; no paid APIs) -->
  <script src="https://unpkg.com/tone@14.8.49/build/Tone.js"></script>
  <script src="https://unpkg.com/meyda/dist/web/meyda.min.js"></script>
  <script src="https://unpkg.com/web-audio-beat-detector/dist/index.umd.js"></script>
  <style>
    :root{ --bg:#070a0f; --ink:#e6f0ff; --accent:#00e5ff; --accent2:#a855f7; }
    html,body{height:100%;background:
      radial-gradient(1200px 800px at 80% -10%, rgba(168,85,247,.12), transparent),
      radial-gradient(1000px 700px at -10% 110%, rgba(0,229,255,.10), transparent),
      var(--bg);color:var(--ink)}
    .title{font-weight:900;letter-spacing:.4px;background:linear-gradient(90deg,var(--accent),var(--accent2));-webkit-background-clip:text;background-clip:text;color:transparent}
    .drop{border:2px dashed rgba(255,255,255,.22);border-radius:16px;padding:28px;text-align:center;cursor:pointer;transition:.2s}
    .drop.drag{border-color:var(--accent);background:rgba(0,229,255,.06)}
    .glass{background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.08);backdrop-filter:blur(8px)}
    .link{color:var(--accent)}
    .row{display:flex;align-items:center;gap:.75rem;justify-content:space-between}
    .btn{border:1px solid rgba(255,255,255,.15);border-radius:14px;padding:.65rem .9rem;min-height:44px}
  </style>
</head>
<body>
  <main class="max-w-2xl mx-auto p-5 min-h-screen flex flex-col gap-6">
    <h1 class="title text-4xl text-center mt-8">GHOSTLOOP</h1>
    <section id="panel" class="glass rounded-2xl p-4">
      <div id="dz" class="drop">
        <p class="text-center">Drag & drop a <b>.wav/.aif/.mp3</b><br/><span class="text-xs text-slate-400">No uploads. All processing is local.</span></p>
        <input id="file" class="hidden" type="file" accept=".wav,.aif,.aiff,.mp3,.flac,.m4a,audio/*"/>
      </div>
      <p id="status" class="text-xs text-slate-400 mt-3">Waiting for file…</p>
      <!-- Variants container appears after render -->
      <div id="variants" class="mt-3 hidden"></div>
    </section>
    <p class="text-[11px] text-slate-500 text-center">This prototype rearranges very short grains from your loop to craft new music. Avoid dragging copyrighted material you can’t legally use in a composition.</p>
  </main>

<script>
// ====== Audio context & constants (free, local-only) ======
const AC = new (window.AudioContext||window.webkitAudioContext)();
const MAX_SECS = 8;           // analyze/slice first 8s only
const NUM_VARIANTS = 5;       // render 5 options
const MAX_RETRIES = 2;        // anti-recognition retries per variant

// State
let srcBuf = null;            // original AudioBuffer (first 8s)
let srcFeat = null;           // {chroma:[12], mfcc:[n]}
let bpm = 100;                // detected bpm fallback
let activePlayers = new Map();// optionIndex -> {playing, stop()}

// UI
const dz = document.getElementById('dz');
const file = document.getElementById('file');
const statusEl = document.getElementById('status');
const variantsEl = document.getElementById('variants');
const db = (m)=> statusEl.textContent = m;

// ====== Helpers ======
function toMono(buf){
  if (buf.numberOfChannels===1) return buf;
  const out = AC.createBuffer(1, buf.length, buf.sampleRate);
  const L = buf.getChannelData(0), R = buf.getChannelData(1);
  const ch = out.getChannelData(0);
  for(let i=0;i<buf.length;i++) ch[i] = 0.5*(L[i]+R[i]);
  return out;
}
function firstSeconds(buf, secs){
  const n = Math.min(buf.length, Math.floor(secs*buf.sampleRate));
  const out = AC.createBuffer(1, n, buf.sampleRate);
  out.copyToChannel(toMono(buf).getChannelData(0).subarray(0,n), 0);
  return out;
}
async function resampleTo(buf, targetSR=22050){
  const off = new OfflineAudioContext(1, Math.ceil(buf.duration*targetSR), targetSR);
  const src = off.createBufferSource(); src.buffer = buf; src.connect(off.destination); src.start();
  return await off.startRendering();
}

// Meyda features (chroma + mfcc) averaged across frames
function avg(arrays){ const n = arrays.length||1; const out = new Array(arrays[0].length).fill(0); for(const a of arrays){ for(let i=0;i<a.length;i++) out[i]+=a[i]; } return out.map(v=> v/n); }
function norm(v){ const s = Math.hypot(...v) || 1; return v.map(x=> x/s); }
function cosine(a,b){ const na=norm(a), nb=norm(b); let s=0; for(let i=0;i<na.length;i++) s += (na[i]||0)*(nb[i]||0); return s; }
async function featuresFromBuffer(buf){
  const sr = buf.sampleRate; const sig = buf.getChannelData(0);
  const frameSize = 2048, hop = 1024; const frames = Math.max(0, Math.floor((sig.length-frameSize)/hop));
  const chromas=[], mfccs=[];
  for(let i=0;i<frames;i++){
    const frame = sig.subarray(i*hop, i*hop + frameSize);
    const ch = Meyda.extract('chroma', frame, { sampleRate: sr, bufferSize: frameSize, hopSize: hop });
    const mf = Meyda.extract('mfcc', frame, { sampleRate: sr, bufferSize: frameSize, hopSize: hop, numberOfMFCCCoefficients: 13 });
    if (ch) chromas.push(ch); if (mf) mfccs.push(mf);
    if (i%10===0) await new Promise(r=>setTimeout(r,0));
  }
  return { chroma: chromas.length? avg(chromas) : new Array(12).fill(0), mfcc: mfccs.length? avg(mfccs) : new Array(13).fill(0) };
}

// Anti-recognition guard: low chroma cosine + low MFCC cosine (i.e., less similar)
function isTooSimilar(renderFeat, srcFeat){
  const chromaSim = cosine(renderFeat.chroma, srcFeat.chroma);   // 0..1
  const mfccSim   = cosine(renderFeat.mfcc, srcFeat.mfcc);       // 0..1
  // thresholds tuned to be safe but musical; lower is more different
  return (chromaSim >= 0.55) || (mfccSim >= 0.80);
}

// Simple BPM using external lib
async function detectBPM(buf){
  try{ const b = await window.webAudioBeatDetector.getBpm(buf); return Math.round(b); }
  catch(e){ console.warn('BPM fail', e); return 100; }
}

// ====== Variant renderer (granular from source) ======
async function renderVariant(optionIndex, seed=0){
  await Tone.start();
  Tone.Transport.stop(); Tone.Transport.cancel(0);
  Tone.Transport.bpm.value = bpm;

  // FX chain for modern finish
  const comp = new Tone.Compressor({threshold:-18, ratio:3}).toDestination();
  const limiter = new Tone.Limiter(-0.9).toDestination();
  comp.connect(limiter);
  const reverb = new Tone.Reverb({decay:2.0, wet:0.12}).connect(comp);
  const delay  = new Tone.FeedbackDelay({delayTime:0.25, feedback:0.22, wet:0.10}).connect(comp);
  const eq     = new Tone.EQ3({low:0, mid:0, high:1}).connect(comp);
  const widen  = new Tone.StereoWidener({ width: 0.3 }).connect(comp);

  // One buffer reused via GrainPlayers (keeps "same material")
  const tBuf = new Tone.ToneAudioBuffer(srcBuf);
  const gA = new Tone.GrainPlayer({ url: tBuf, grainSize: 0.06, overlap: 0.02, loop:false }).connect(eq);
  const gB = new Tone.GrainPlayer({ url: tBuf, grainSize: 0.09, overlap: 0.03, loop:false }).connect(reverb);
  const gC = new Tone.GrainPlayer({ url: tBuf, grainSize: 0.04, overlap: 0.02, loop:false }).connect(delay);
  const gD = new Tone.GrainPlayer({ url: tBuf, grainSize: 0.08, overlap: 0.02, loop:false, playbackRate: 0.98 }).connect(widen);
  [gA,gB,gC,gD].forEach(g=> g.sync().start(0));

  // Seeded randomness
  let s = seed>>>0; const rnd = () => (s = (s*1664525 + 1013904223)>>>0, (s & 0xffff)/0xffff);

  // Params per variant (density/swing/jitter/pitch)
  const bars = 8; const swing = (rnd()*0.18); const density = 0.30 + rnd()*0.25; const jitter = rnd()*0.08; const semi = Math.round((rnd()*2-1)*2); // ±2 semitones

  // Schedule events (re-sequenced grains)
  const ev=[]; const secPerBeat = 60/(bpm||100);
  function pickOffset(){ return rnd()*Math.max(0.01, srcBuf.duration - 0.12); }
  function t(b, sixteenth){
    const base = `${b}:${Math.floor(sixteenth/4)}:${sixteenth%4}`;
    // swing: delay odd 8ths a bit
    const isOdd8 = (sixteenth%8)>=4; const swingMs = isOdd8? swing*secPerBeat*1000*0.5 : 0;
    return { time: base, swingMs };
  }
  for(let b=0;b<bars;b++){
    // backbeat accents on new pattern
    ev.push({ ...t(b,4),  which:'A', off:pickOffset(), rate: 1 + (rnd()*0.02-0.01) });
    ev.push({ ...t(b,12), which:'B', off:pickOffset(), rate: 1 + (rnd()*0.02-0.01) });
    for(let s16=0;s16<16;s16++){
      if (Math.random()<density){
        const sel = rnd(); const which = sel<0.4?'C': sel<0.8?'D':'A';
        ev.push({ ...t(b,s16), which, off: pickOffset(), rate: 1 + (rnd()*0.04-0.02) });
      }
    }
  }

  // Pitch nudge (quantized to semitones via playbackRate)
  const pitchRate = Math.pow(2, semi/12);

  const part = new Tone.Part((time, d)=>{
    const when = time + (d.swingMs||0)/1000;
    const startAt = Math.max(0, d.off);
    const rate = (d.rate||1) * pitchRate;
    if (d.which==='A') gA.start(when, startAt, 0.12, rate);
    if (d.which==='B') gB.start(when, startAt, 0.12, rate);
    if (d.which==='C') gC.start(when, startAt, 0.10, rate);
    if (d.which==='D') gD.start(when, startAt, 0.10, rate);
  }, ev).start(0);

  // Record this variant
  const rec = new Tone.Recorder();
  Tone.getDestination().connect(rec);
  Tone.Transport.start();
  const seconds = (bars*4) * (60/(bpm||100));
  rec.start();
  const blob = await new Promise(resolve=> setTimeout(async ()=> resolve(await rec.stop()), (seconds+0.25)*1000));
  Tone.Transport.stop(); part.dispose(); [gA,gB,gC,gD].forEach(g=> { try{ g.stop(); g.dispose(); }catch(_){} });

  const url = URL.createObjectURL(blob);
  return { url, blob };
}

// Compute features from a WAV Blob by decoding it
async function featuresFromBlob(blob){
  const ab = await blob.arrayBuffer();
  const buf = await AC.decodeAudioData(ab);
  const slim = firstSeconds(buf, Math.min(8, buf.duration));
  return await featuresFromBuffer(slim);
}

// Generate 5 variants sequentially with anti-recognition guard
async function generateFive(){
  variantsEl.innerHTML = '';
  variantsEl.classList.remove('hidden');
  const rows = [];
  for(let i=1;i<=NUM_VARIANTS;i++){
    const row = document.createElement('div');
    row.className = 'glass rounded-xl p-3 row';
    row.innerHTML = `<div class="text-sm">Option ${i}</div>
      <div class="flex gap-2">
        <button class="btn" data-play>Play</button>
        <a class="btn link" data-dl download="ghostloop_option-${i}.wav">Download</a>
      </div>`;
    variantsEl.appendChild(row);
    rows.push(row);
  }

  // sequential render
  for(let i=1;i<=NUM_VARIANTS;i++){
    db(`Rendering ${i}/${NUM_VARIANTS}…`);
    let tries=0, final=null, feat=null;
    while(tries<=MAX_RETRIES){
      const seed = (Math.random()*1e9)|0;
      const { url, blob } = await renderVariant(i, seed);
      feat = await featuresFromBlob(blob);
      if (!isTooSimilar(feat, srcFeat)) { final = {url, blob}; break; }
      URL.revokeObjectURL(url); tries++;
    }
    if (!final){ // accept last try anyway to avoid blocking
      const { url, blob } = await renderVariant(i, (Math.random()*1e9)|0);
      final = { url, blob };
    }
    // wire controls
    const row = rows[i-1];
    const playBtn = row.querySelector('[data-play]');
    const dl = row.querySelector('[data-dl]');
    dl.href = final.url;

    // simple player per row (use HTMLAudioElement to avoid reusing Transport)
    const audio = new Audio(final.url);
    activePlayers.set(i, { playing:false, stop:()=>{ audio.pause(); audio.currentTime=0; activePlayers.get(i).playing=false; playBtn.textContent='Play'; } });

    playBtn.onclick = ()=>{
      // stop all others
      for(const [k,p] of activePlayers){ if(k!==i && p.playing){ p.stop(); } }
      const p = activePlayers.get(i);
      if (!p.playing){ audio.currentTime=0; audio.play(); p.playing=true; playBtn.textContent='Stop';
        audio.onended = ()=>{ p.playing=false; playBtn.textContent='Play'; };
      } else { p.stop(); }
    };
  }
  db('Done. Pick your favorite.');
}

// ====== Main pipeline ======
async function processFile(f){
  db('Decoding…');
  const ab = await f.arrayBuffer();
  const buf = await AC.decodeAudioData(ab);
  srcBuf = firstSeconds(buf, MAX_SECS);
  const slim = await resampleTo(srcBuf, 22050);
  db('Analyzing…');
  try { bpm = await detectBPM(slim); } catch(_) { bpm = 100; }
  srcFeat = await featuresFromBuffer(slim);
  db(`BPM ${bpm} — generating 5 options…`);
  await generateFive();
}

// ====== Minimal UI wiring ======
dz.addEventListener('click', ()=> file.click());
file.addEventListener('change', e=> handleDropFiles(e.target.files));
dz.addEventListener('dragover', e=>{ e.preventDefault(); dz.classList.add('drag'); });
dz.addEventListener('dragleave', ()=> dz.classList.remove('drag'));
dz.addEventListener('drop', e=>{ e.preventDefault(); dz.classList.remove('drag'); const dt=e.dataTransfer; if(dt?.files&&dt.files.length) handleDropFiles(dt.files); else db('Drag the actual audio file (export from Splice first).'); });
function handleDropFiles(files){
  const f = files?.[0];
  if(!f){ db('No audio file detected.'); return; }
  if(!f.type.startsWith('audio') && !/\.(wav|aif|aiff|mp3|flac|m4a)$/i.test(f.name||'')){
    db('Not an audio file. Use .wav/.aif/.mp3'); return; }
  // reset previous
  for(const [,p] of activePlayers){ try{ p.stop(); }catch(_){} }
  activePlayers.clear();
  if (variantsEl){ variantsEl.innerHTML=''; variantsEl.classList.add('hidden'); }
  processFile(f).catch(e=>{ console.error(e); db('Error while processing. Try a shorter loop (4–16 bars).'); });
}
</script>
</body>
</html>
